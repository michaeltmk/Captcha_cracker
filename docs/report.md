# Captcha_cracker
A demonstration on cracking Captcha using CNN.

## Abstract
Deep learning can be used in many application and computer vision is one of the mainstream. This is a demonstration of recognizing captcha using deep neural network (DNN).
Captchas with 4 characters were scrapped on the web.
In total there are 384 captcha images, 128 for the training set, 128 for the dev set, 128 for the test set.
For each epoch, 128 more images are generated by a captcha simulator and together 256 images are fed into the model for training. The training will be stopped when the accuracy of the dev set is above 0.9.

After training the model, it was tested on the test set and had a very good result, the model is fine-tuned.

Hence the dev set is moved to the training set. The model has trained again with the same setting but a larger training set.

## Data Preparation
Captchas were scrapped on a single website. As inspected, each captcha image contains 4 characters, which can only be capital size English letters (without F, G, I, L, O, Q, Z) or numbers (3, 4, 6, 8, 9). There are 24 possibilities for each character, in other words, there are 331776 possible "answers".

In total there were 384 captcha images collected from web scrapping and labeled manually. They were separated into three sets: 128 for the training set, 128 for the dev set, 128 for the test set. This is absolutely not enough for training a  DNN, however collecting and labeling data is time costing and hence a captcha generator was used to generate new captchas for training.

The data were clean and only black and white in colour which was ready to feed into the DNN. I tried to do feature scaling using mean normalization but it did not affect the preformance(accucy of the dev set) or even worst so I dropped it, this may be because there are already batch normalization layers in the DNN model.

The training set was a combination of raw images and generated images. In each epoch, a new batch with all 128 raw images and 128 new generated images is used for training to ensure the raw images having a high enough weight in the training process. The raw/generated ratio is tuned together with the style of captcha generator as they are both causing overfitting problem of training set with respect to dev set. However, repeacting the raw images in each epoch may have high risk of overfitting these 128 images. This can verified by dev set.

## Data Preparation: Captcha Generator
In general, image data augmentation techniques such as rotation, translation, flipping, contrast adjustment or brightness adjustment are quite common in generating new images for DNN training. However, these are not useful in this case as the raw captcha images are too low in quantity and it did not collect all possible labels. Which means even applied all kind of data augmentation techniques in the raw data set, there is still bias. Besides, as inspected, the captcha images are similar in shape and style, a simulator that generates new captcha with a similar style as raw data will be more suitable.

A python library called ImageCaptcha was used. The style of the output was tuned by direct comparing with the raw images using human vision. There is no standard numarical system to comapre two images' styles and hence the tuning of generator may not be perfect. However, it will result in a clearly overfitting problem if the generated images are not similar to raw data.

## Modeling
The DNN model had 78 CNN layers, including 5 downsampling layers which in total downscale by a factor of 32, then followed by 2 full connected layers.
Within each downsampling layers, 2 to 8 residual blocks with kernel_size 1x1,3x3,1x1 are added in order to carry the detail features along to a deeper layer.leaky_relu is used to prevent “dying ReLU” problem. 
Batch normalization but no dropout is used after conv layer, as it brings significant improvements in convergence while preventing overfitting.
## Evaluation
## Evaluation: Hyperparameter tuning
## Deployment